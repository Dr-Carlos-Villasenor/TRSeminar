{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPivtBy9WAK1CoBnNeJvkxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Carlos-Villasenor/TRSeminar/blob/main/TRS13_NN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Seminar\n",
        "## Dr. Carlos Villaseñor\n",
        "## Neural nets from scratch"
      ],
      "metadata": {
        "id": "NwqTUWuxYMQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Basic modules and functions"
      ],
      "metadata": {
        "id": "AhoJLbMxYVty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wKjED1KUYfRe"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A help function to draw"
      ],
      "metadata": {
        "id": "Y3yKo7oxPAT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for drawing the neuron geometry\n",
        "def draw_2d_percep(model):\n",
        "  w1, w2, b = model.w[0], model.w[1], model.b\n",
        "  plt.plot([-2, 2],[(1/w2)*(-w1*(-2)-b),(1/w2)*(-w1*2-b)],'--k')"
      ],
      "metadata": {
        "id": "OtPW6h-cO_vM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OLN_plot_data(X, Y, net):\n",
        "  dot_c = ('red', 'green', 'blue', 'black')\n",
        "  lin_c = ('r-', 'g-', 'b-', 'k-')\n",
        "  for i in range(X.shape[1]):\n",
        "      c = np.argmax(Y[:,i])\n",
        "      plt.scatter(X[0,i], X[1,i], color=dot_c[c], edgecolors='k')\n",
        "\n",
        "  for i in range(4):\n",
        "      w1, w2, b = net.w[i,0], net.w[i,1], net.b[i]\n",
        "      plt.plot([-0.25, 1.25],[(-1/w2)*(w1*(-0.25)+b),(-1/w2)*(w1*(1.25)+b)], lin_c[i])\n",
        "\n",
        "\n",
        "  #plt.axis('equal')\n",
        "  plt.xlim([-0.25, 1.25])\n",
        "  plt.ylim([-0.25, 1.25])"
      ],
      "metadata": {
        "id": "1AfKmh8xTgRk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_binary_classification_2d(X,Y,net):\n",
        "    plt.figure()\n",
        "    for i in range(X.shape[1]):\n",
        "        if Y[0,i]==0:\n",
        "            plt.plot(X[0,i], X[1,i], '.r')\n",
        "        else:\n",
        "            plt.plot(X[0,i], X[1,i], '.b')\n",
        "    xmin, ymin=np.min(X[0,:])-0.5, np.min(X[1,:])-0.5\n",
        "    xmax, ymax=np.max(X[0,:])+0.5, np.max(X[1,:])+0.5\n",
        "    xx, yy = np.meshgrid(np.linspace(xmin,xmax,100),\n",
        "                         np.linspace(ymin,ymax,100))\n",
        "    data = [xx.ravel(), yy.ravel()]\n",
        "    zz = net.predict(data)\n",
        "    zz = zz.reshape(xx.shape)\n",
        "    plt.contourf(xx,yy,zz, alpha=0.8,\n",
        "                 cmap=plt.cm.RdBu)\n",
        "    plt.xlim([xmin,xmax])\n",
        "    plt.ylim([ymin,ymax])\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5JmFGmdgQXbH"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McCulluch and Pitts Neuron"
      ],
      "metadata": {
        "id": "6_Dm_rJLKzO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a neuron from scratch"
      ],
      "metadata": {
        "id": "eLLpPjoKYh1Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zShXwHkCOmEm"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "  def __init__(self, n_inputs):\n",
        "    # Inicialize the neuron parameters\n",
        "    self.w = - 1 + 2 * np.random.rand(n_inputs)\n",
        "    self.b = - 1 + 2 * np.random.rand()\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Get number of inputs\n",
        "    _, p = X.shape\n",
        "\n",
        "    # Create outut matrix\n",
        "    y_est = np.zeros(p)\n",
        "\n",
        "    for i in range(p):\n",
        "      y_est[i] = np.dot(self.w, X[:,i]) + self.b\n",
        "      if y_est[i] >= 0:\n",
        "        y_est[i] = 1\n",
        "      else:\n",
        "        y_est[i] = 0\n",
        "    return y_est"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block draw the class of each point in the plane"
      ],
      "metadata": {
        "id": "3zQjTYVXbHlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para dibujar superficie de desición\n",
        "def draw_2d_percep(model):\n",
        "  w1, w2, b = model.w[0], model.w[1], model.b\n",
        "  plt.plot([-5, 5],[(1/w2)*(-w1*(-5)-b),(1/w2)*(-w1*5-b)],'--k')\n",
        "\n",
        "# Instanciamos la neurona\n",
        "net = Neuron(2)\n",
        "\n",
        "# Preparar datos\n",
        "xmin, ymin = -5, -5\n",
        "xmax, ymax = 5, 5\n",
        "xx, yy = np.meshgrid(np.linspace(xmin,xmax, 100),\n",
        "                     np.linspace(ymin,ymax, 100))\n",
        "X = np.concatenate((xx.reshape(-1,1), yy.reshape(-1,1)), axis=1).T\n",
        "\n",
        "# Predecir cada punto\n",
        "y_est = net.predict(X)\n",
        "zz = y_est.reshape(xx.shape)\n",
        "\n",
        "# Dibujar\n",
        "plt.figure()\n",
        "plt.title('Espacio geométrico de la Neurona de McCulluch-Pitts')\n",
        "draw_2d_percep(net)\n",
        "plt.contourf(xx, yy, zz, cmap=plt.cm.RdBu)\n",
        "plt.xlim([xmin,xmax])\n",
        "plt.ylim([ymin,ymax])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xcAybgM7bGZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron algorithm"
      ],
      "metadata": {
        "id": "ZQ8E0RWjK7AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's code a Perceptron from scratch"
      ],
      "metadata": {
        "id": "tg6xlN1WLMfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "\n",
        "  def __init__(self, n_inputs):\n",
        "    self.w = - 1 + 2 * np.random.rand(n_inputs)\n",
        "    self.b = - 1 + 2 * np.random.rand()\n",
        "\n",
        "  def predict(self, X):\n",
        "    _, p = X.shape\n",
        "    y_est = np.zeros(p)\n",
        "    for i in range(p):\n",
        "      y_est[i] = np.dot(self.w, X[:,i])+self.b\n",
        "      if y_est[i] >= 0:\n",
        "        y_est[i]=1\n",
        "      else:\n",
        "        y_est[i]=0\n",
        "    return y_est\n",
        "\n",
        "  def fit(self, X, Y, learning_rate=0.1, epochs=50):\n",
        "    _, p = X.shape\n",
        "    for _ in range(epochs):\n",
        "      for i in range(p):\n",
        "        y_est = self.predict(X[:,i].reshape(-1,1))\n",
        "        self.w += learning_rate * (Y[i]-y_est) * X[:,i]\n",
        "        self.b += learning_rate * (Y[i]-y_est)"
      ],
      "metadata": {
        "id": "kMjCLREHLBtP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block with train a neuron to approach the \"OR\" logical gate"
      ],
      "metadata": {
        "id": "11-tg6sQLf71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = Perceptron(2)\n",
        "\n",
        "# Datos\n",
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]])\n",
        "Y = np.array( [0, 1, 1, 1])\n",
        "\n",
        "# fit the model\n",
        "model.fit(X,Y)\n",
        "\n",
        "# Make prediction\n",
        "model.predict(X)\n",
        "\n",
        "# Draw input data and neuron\n",
        "_, p = X.shape\n",
        "for i in range(p):\n",
        "  if Y[i] == 0:\n",
        "    plt.plot(X[0,i],X[1,i], 'or')\n",
        "  else:\n",
        "    plt.plot(X[0,i],X[1,i], 'ob')\n",
        "\n",
        "plt.title('Perceptron')\n",
        "plt.grid('on')\n",
        "plt.xlim([-2,2])\n",
        "plt.ylim([-2,2])\n",
        "plt.xlabel(r'x1')\n",
        "plt.ylabel(r'x2')\n",
        "\n",
        "draw_2d_percep(model)"
      ],
      "metadata": {
        "id": "hcIJ2_JWLYa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Linear Neuron"
      ],
      "metadata": {
        "id": "zw8vkuu7MbVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_Neuron:\n",
        "\n",
        "  def __init__(self, n_inputs, learning_rate=0.1):\n",
        "    self.w = - 1 + 2 * np.random.rand(n_inputs)\n",
        "    self.b = - 1 + 2 * np.random.rand()\n",
        "    self.eta = learning_rate\n",
        "\n",
        "  def predict(self, X):\n",
        "    Y_est = np.dot(self.w, X) + self.b\n",
        "    return Y_est\n",
        "\n",
        "  def train(self, X, Y, epochs=50, solver='BGD'):\n",
        "    _, p = X.shape\n",
        "    for _ in range(epochs):\n",
        "      if solver == 'SGD':\n",
        "        for i in range(p):\n",
        "            y_est = self.predict(X[:,i])\n",
        "            self.w += self.eta * (Y[:,i]-y_est) * X[:,i]\n",
        "            self.b += self.eta * (Y[:,i]-y_est)\n",
        "      elif solver == 'BDG':\n",
        "        Y_est = self.predict(X)\n",
        "        # Completa las siguientes líneas de código\n",
        "        self.w += (self.eta/p) * ((Y - Y_est) @ X.T).ravel()\n",
        "        self.b += (self.eta/p) * np.sum(Y - Y_est)"
      ],
      "metadata": {
        "id": "1bahGndoMwyh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data\n",
        "p =100\n",
        "x = -1 + 2 * np.random.rand(p).reshape(1,-1)\n",
        "y = -18 * x + 6 + 3 * np.random.randn(p)\n",
        "plt.plot(x,y,'.b')\n",
        "\n",
        "\n",
        "neuron = Linear_Neuron(1, 0.1)\n",
        "neuron.train(x,y,solver='BDG', epochs=100 )\n",
        "\n",
        "# Draw neuron\n",
        "xn = np.array([[-1, 1]])\n",
        "plt.plot(xn.ravel() ,neuron.predict(xn),'--r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zqQXF6VSMx-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Sigmoid Neuron"
      ],
      "metadata": {
        "id": "7SMeSKEAMfvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid_Neuron:\n",
        "\n",
        "    def __init__(self, n_inputs):\n",
        "        self.w = - 1 + 2 * np.random.rand(n_inputs)\n",
        "        self.b = - 1 + 2 * np.random.rand()\n",
        "\n",
        "    def predict(self, X):\n",
        "        Z = np.dot(self.w, X) + self.b\n",
        "        Y_est = 1/(1+np.exp(-Z))\n",
        "        return Y_est\n",
        "\n",
        "    def fit(self, X, Y, learning_rate=1, epochs=100):\n",
        "        p = X.shape[1]\n",
        "        for _ in range(epochs):\n",
        "            Y_est = self.predict(X)\n",
        "            self.w += (learning_rate/p) * ((Y - Y_est) @ X.T).ravel()\n",
        "            self.b += (learning_rate/p) * np.sum(Y - Y_est)"
      ],
      "metadata": {
        "id": "vTmtdekcN0zQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]])\n",
        "Y = np.array([0, 0, 0, 1])\n",
        "\n",
        "neuron = Sigmoid_Neuron(2)\n",
        "neuron.fit(X,Y)\n",
        "print(neuron.predict(X))\n",
        "\n",
        "\n",
        "# Draw\n",
        "_, p = X.shape\n",
        "for i in range(p):\n",
        "  if Y[i] == 0:\n",
        "    plt.plot(X[0,i],X[1,i], 'or')\n",
        "  else:\n",
        "    plt.plot(X[0,i],X[1,i], 'ob')\n",
        "\n",
        "plt.title('Sigmoid neuron')\n",
        "plt.grid('on')\n",
        "plt.xlim([-2,2])\n",
        "plt.ylim([-2,2])\n",
        "plt.xlabel(r'')\n",
        "plt.ylabel(r'')\n",
        "draw_2d_percep(neuron)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GenfZhY-OYlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-Layer Network"
      ],
      "metadata": {
        "id": "w31mE-r5Qr_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's code some activation functions"
      ],
      "metadata": {
        "id": "4aiwJtzbSc7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions for output layer ------------------------------\n",
        "\n",
        "# Linear neurons are used for regression problems\n",
        "def linear(z, derivative=False):\n",
        "  a = z\n",
        "  if derivative:\n",
        "    da = np.ones(z.shape, dtype=float)\n",
        "    return a, da\n",
        "  return a\n",
        "\n",
        "# Sigmoid neurons are used in multi-label or binary classification problems\n",
        "def sigmoid(z, derivative=False):\n",
        "  a = 1/(1 + np.exp(-z))\n",
        "  if derivative:\n",
        "    da = np.ones(z.shape, dtype=float)\n",
        "    return a, da\n",
        "  return a\n",
        "\n",
        "# Softmax function is used in one-winner multiclass classification problems\n",
        "def softmax(z, derivative=False):\n",
        "  e = np.exp(z - np.max(z, axis=0))\n",
        "  a = e / np.sum(e, axis=0)\n",
        "  if derivative:\n",
        "    da = np.ones(z.shape, dtype=float)\n",
        "    return a, da\n",
        "  return a"
      ],
      "metadata": {
        "id": "Uvp2JFiXQwlo"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the program for a one layer network"
      ],
      "metadata": {
        "id": "TD3w2AWMTGHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OLN:\n",
        "  \"\"\"One-Layer Network\"\"\"\n",
        "\n",
        "  def __init__(self, n_inputs, n_outputs,\n",
        "               activation_funtion=linear):\n",
        "      # Initialize parameters\n",
        "      self.w = - 1 + 2 * np.random.rand(n_outputs, n_inputs)\n",
        "      self.b = - 1 + 2 * np.random.rand(n_outputs, 1)\n",
        "      self.f = activation_funtion\n",
        "\n",
        "  def predict(self, X):\n",
        "      # Propagate the layer\n",
        "      Z = self.w @ X + self.b\n",
        "      return self.f(Z)\n",
        "\n",
        "  def fit(self, X, Y, epochs=1000,  lr=0.1):\n",
        "      # Get the columns of X\n",
        "      p = X.shape[1]\n",
        "\n",
        "      for _ in range(epochs):\n",
        "          # Propagation -----------------------------------------------------\n",
        "          Z = self.w @ X + self.b\n",
        "          Yest, dY = self.f(Z, derivative=True)\n",
        "\n",
        "          # Training --------------------------------------------------------\n",
        "\n",
        "          # Calculate local gradient\n",
        "          lg = (Y - Yest) * dY\n",
        "\n",
        "          # Update parameters\n",
        "          self.w += (lr/p) * lg @ X.T\n",
        "          self.b += (lr/p) * np.sum(lg, axis=1).reshape(-1,1)"
      ],
      "metadata": {
        "id": "D2s5M-sySlrk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get some data to see how the OLN behave"
      ],
      "metadata": {
        "id": "0udoNPcETFhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/Dr-Carlos-Villasenor/TRSeminar/main/Datasets/Dataset_A05.csv'\n",
        "df = pd.read_csv('Dataset_A05.csv')\n",
        "X = np.asanyarray(df.iloc[:,0:2]).T\n",
        "Y = np.asanyarray(df.iloc[:,2:]).T"
      ],
      "metadata": {
        "id": "b_1EpXCuTE5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = OLN(2, 4, sigmoid)\n",
        "net.fit(X, Y, epochs=1000, lr=1)\n",
        "OLN_plot_data(X, Y, net)"
      ],
      "metadata": {
        "id": "ssv8dCuGTQsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Network (Multi-layer Perceptron)"
      ],
      "metadata": {
        "id": "Bd9aUzByVkJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the activations functions for the hidden layers"
      ],
      "metadata": {
        "id": "nUgV3A7uV4gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions for hidden layers -----------------------------\n",
        "\n",
        "def tanh(z, derivative=False):\n",
        "    a = np.tanh(z)\n",
        "    if derivative:\n",
        "        da = (1 - a) * (1 + a)\n",
        "        return a, da\n",
        "    return a\n",
        "\n",
        "\n",
        "def relu(z, derivative=False):\n",
        "    a = z * (z >= 0)\n",
        "    if derivative:\n",
        "        da = np.array(z >= 0, dtype=float)\n",
        "        return a, da\n",
        "    return a\n",
        "\n",
        "def sigmoid_hidden(z, derivative=False):\n",
        "    a = 1/(1 + np.exp(-z))\n",
        "    if derivative:\n",
        "        da = a * (1 - a)\n",
        "        return a, da\n",
        "    return a"
      ],
      "metadata": {
        "id": "4M9qLtTIV5J8"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write the code for the MLP from scratch"
      ],
      "metadata": {
        "id": "hIlOU62fWjm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense_Network:\n",
        "\n",
        "    def __init__(self, layers_dims,\n",
        "                 hidden_activation=tanh,\n",
        "                 output_activation=sigmoid):\n",
        "\n",
        "        # Attributes\n",
        "        self.L = len(layers_dims) - 1\n",
        "        self.w = [None] * (self.L + 1)\n",
        "        self.b = [None] * (self.L + 1)\n",
        "        self.f = [None] * (self.L + 1)\n",
        "\n",
        "        # Initialize weights\n",
        "        for l in range(1, self.L + 1):\n",
        "            self.w[l] = -1 + 2 * np.random.rand(layers_dims[l],\n",
        "                                                layers_dims[l-1])\n",
        "            self.b[l] = -1 + 2 * np.random.rand(layers_dims[l], 1)\n",
        "\n",
        "            if l == self.L:\n",
        "                self.f[l] = output_activation\n",
        "            else:\n",
        "                self.f[l] = hidden_activation\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        a = X\n",
        "        for l in range(1, self.L + 1):\n",
        "            z = np.dot(self.w[l], a) + self.b[l]\n",
        "            a = self.f[l](z)\n",
        "        return a\n",
        "\n",
        "    def fit(self, X, Y, epochs=500, lr=0.1):\n",
        "        p = X.shape[1]\n",
        "        for _ in range(epochs):\n",
        "\n",
        "            # initialize activations containers\n",
        "            a = [None] * (self.L + 1)\n",
        "            da = [None] * (self.L + 1)\n",
        "            lg = [None] * (self.L + 1)\n",
        "\n",
        "            # Propagation\n",
        "            a[0] = X\n",
        "            for l in range(1, self.L + 1):\n",
        "                z = np.dot(self.w[l], a[l-1]) + self.b[l]\n",
        "                a[l], da[l] = self.f[l](z, derivative=True)\n",
        "\n",
        "            # Backpropagation\n",
        "            for l in range(self.L, 0, -1):\n",
        "                if l == self.L:\n",
        "                    lg[l] = -(Y - a[l]) * da[l]\n",
        "                else:\n",
        "                    lg[l] = np.dot(self.w[l+1].T, lg[l + 1]) * da[l]\n",
        "\n",
        "            # Gradient Descent\n",
        "            for l in range(1, self.L + 1):\n",
        "                self.w[l] -= (lr/p) * np.dot(lg[l], a[l - 1].T)\n",
        "                self.b[l] -= (lr/p) * np.sum(lg[l])\n"
      ],
      "metadata": {
        "id": "EnZmWZBIWqoK"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XOR problem"
      ],
      "metadata": {
        "id": "hPVNt1-4XG4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]])\n",
        "Y = np.array([[1, 0, 0, 1]])\n",
        "\n",
        "\n",
        "net = Dense_Network((2,100,1))\n",
        "net.fit(X, Y)\n",
        "print(net.predict(X))\n",
        "MLP_binary_classification_2d(X,Y,net)"
      ],
      "metadata": {
        "id": "u0ISOUBkXJcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blobs"
      ],
      "metadata": {
        "id": "luuDLFBdXfUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/Dr-Carlos-Villasenor/TRSeminar/main/Datasets/blobs.csv'\n",
        "df = pd.read_csv('blobs.csv')\n",
        "X = np.asanyarray(df[['x1', 'x2']]).T\n",
        "Y = np.asanyarray(df[['y']]).T"
      ],
      "metadata": {
        "id": "g09EE5IkXhdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Dense_Network((2,100,1))\n",
        "net.fit(X, Y)\n",
        "MLP_binary_classification_2d(X,Y,net)"
      ],
      "metadata": {
        "id": "-N3PN8gnXaqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moons"
      ],
      "metadata": {
        "id": "NbZYrENQX5Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/Dr-Carlos-Villasenor/TRSeminar/main/Datasets/moons.csv'\n",
        "df = pd.read_csv('moons.csv')\n",
        "X = np.asanyarray(df[['x1', 'x2']]).T\n",
        "Y = np.asanyarray(df[['y']]).T"
      ],
      "metadata": {
        "id": "jftNBWwoX7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Dense_Network((2,100,1))\n",
        "net.fit(X, Y)\n",
        "MLP_binary_classification_2d(X,Y,net)"
      ],
      "metadata": {
        "id": "fKF7zF4aX90L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Circles"
      ],
      "metadata": {
        "id": "GHxKpqn_YH6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/Dr-Carlos-Villasenor/TRSeminar/main/Datasets/circles.csv'\n",
        "df = pd.read_csv('circles.csv')\n",
        "X = np.asanyarray(df[['x1', 'x2']]).T\n",
        "Y = np.asanyarray(df[['y']]).T"
      ],
      "metadata": {
        "id": "n2D5Rn2MYJvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Dense_Network((2,100,1))\n",
        "net.fit(X, Y)\n",
        "MLP_binary_classification_2d(X,Y,net)"
      ],
      "metadata": {
        "id": "DBu4GaKmYOET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}